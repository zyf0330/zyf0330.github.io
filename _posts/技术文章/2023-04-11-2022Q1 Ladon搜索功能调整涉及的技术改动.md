---
layout: post
title: '2022Q1 Ladon搜索功能调整涉及的技术改动.md'
date: 2023-04-11
category: 技术文章
---

## 搜索功能简介

最近几个迭代，pingcode 的搜索功能新增了附件和评论数据的搜索，另外对于原来已经支持的工作项、测试用例和页面等类型的搜索，覆盖了更多可搜索内容，包括编号、描述、自定义属性和更多页面内容类型。

在完成这些功能的时，我们为附件和评论的数据写入开发了新的 ES 同步器，另外对搜索过程进行了调优，一方面是对搜索结果的精确度和排序调优，另一方面是引入新的可见性判断流程和大数据分页方式。

## 搜索功能的技术实现

先介绍一下整个搜索功能后端的架构（不包括 Elasticsearch 基础设施本身）

搜索功能后端是由 ladon 基于 Elasticsearch ，并且结合几个底层库提供的。其中

- Chaos 在最底层提供 ES 相关数据结构类型，持有 ES client sdk 的全局实例，以及基于 Repository 将数据写入到ES的插件。这个插件负责将工作项、测试用例、页面的数据改动写入到 ES 中。
- Eros 提供 ES index 的 config 配置，以及负责连接 ES client 到 ES 数据库。
- pc-core 紧贴业务，站在子产品的业务对象这层封装了 Chaos 的 ES 同步插件和数据类型，另外为附件和评论数据提供了单独的同步器。
- 各个子产品通过使用 pc-core 的 ES 同步插件和同步器，在相关业务对象数据变更时写入到 ES 中。
- Ladon 在最上层，面向前端提供对多个子产品各类 ES 数据的检索能力，对各种搜索条件的组装和搜索结果的处理都在这里


## 重要的技术点

### 为附件和评论数据封装新的同步器

  @zhaoyunfeng   

之前工作项、测试用例和页面的搜索，是基于 Chaos 提供的 ES 同步插件将数据写入到 ES 中的。这个同步插件的特点，是将一种 Entity （有对应的 Repository）的数据变更映射到对应的 ES Entity 数据，根据数据是插入/更新还是删除，来将数据替换插入到 ES 或从 ES 删除。它对于直接将数据本身映射到 ES 的场景支持很好，但是有一些业务场景，需要将数据本身关联的其他数据的变更映射为该数据的变更，此时这个同步插件就无法很好的支持了。举个这样的业务场景的例子，比如删除项目导致的工作项删除，或者删除工作项导致的关联评论的删除。

到了附件和评论，就和之前的三种数据更不一样了，附件和评论在 ES 中需要被记录和搜索的信息除了它们本身，还包括关联的 BroadObject 、文件本身信息、评论本身信息和评论关联的附件信息，也就是说评论和附件的 ES Entity 由几种 Entity 组合而成，另外评论和附件本身并不是 Entity（没有对应的 Repository），因此之前的基于 Repository 的同步插件几乎无法工作。

所以现在我们需要一种新的 ES 同步器，抛弃 Entity transform to ES Entity 的部分，并且支持更为自由的 find and replace 方式来更新部分字段，以更有效地支持复杂的业务场景。


新的同步器剔除了   `transform`  方法，由外部组装和传入 ES Entity，并且提供了三种数据变更动作：

-   `index`   根据 id 来 upsert 数据
-   `unIndex`   根据 id 来删除数据
-   `bulkFindAndReplace`   根据指定条件查询并替换指定字段


> 目前还没有类似于 erase 指定项目的所有工作项的场景

具体的代码实现可以自行查看 pc-core 的   `src/elasticsearch/es-synchronizer.ts`  ，等到这部分功能稳定以后，这个同步器理应放入 chaos 作为基础 ES 组件的一部分。

然后再基于这个同步器，为评论相关的业务场景封装更新评论数据的评论同步器。有兴趣的可以参见   `src/elasticsearch/comment/es-comment-synchronizer.ts`  ，这里就不赘述实现细节了。


### 新的可见性判断流程和大数据分页方式

  @zhaoyunfeng   

前不久 Wiki 修改了页面对于团队成员的可查看性和可编辑性的权限体系，引入了更为复杂的可见性判断逻辑，和其他子产品的逻辑截然不同。之前搜索页面使用的判断  **搜索者是否属于知识库成员或是否属于参与人**  的简单逻辑，已经不能满足需要。同时，我们也不希望将这套复杂的权限判断逻辑在 Ladon 中再复刻一份（这样会引入额外的开发成本和双倍的维护成本）。

因此我们决定修改可见性判断流程，改为先搜索再过滤的方式。过滤阶段通过使用 Wiki 提供的 rpc 来将搜索人不可见的页面过滤掉，来确保可见性判断逻辑只需要在 Wiki 代码库中实现一次。



然而这又导致了一个新的问题，搜索时预期的分页信息和返回数据的分页信息对不上了。

先看一下现有的分页信息

```
export interface Pagination {
    count: number;
    page_index: number;
    page_size: number;
    page_count: number;
}
```

在查询涉及分页的数据时，由前端指定   `page_index`   和   `page_size`   来请求分页数据，而这里经过过滤后的数据，已经和其在 ES 中的分页位置偏移了。随之而来的影响是，搜索结果的总数即   `count`  也变得无法确定。

因此这里再引入一种新的分页类型，在大部分兼容之前分页交互方式的同时、又支持此种场景的分页展示。我叫做大数据分页 BigdataPagination。这里先介绍一下这个分页方式本身，再介绍它如何支持搜索结果数据的分页。

```
export type BigdataCursor = string;
export type BigdataPageInfo = { data_cursor?: BigdataCursor };
export type BigdataPaging = {
    page_index: number;
    page_size: number;
    /**
     * 当前页前后分别希望加载的最大页数
     */
    one_side_page_count: number;
} & BigdataPageInfo;
export type BigdataPagination = {
    page_index: number;
    page_size: number;
    /**
     * 实际加载到的页
     */
    pages: ({ page_index: number } & BigdataPageInfo)[];
    /**
     * 从第一页开始直到实际加载到的最后页的数据总数
     */
    count: number;
};
```

比较原有的分页，大数据分页抛弃了   `page_count`   和   `count`  （这里的 count 是从第一页到当前已知的页的数据量），现在你无从得知总共有多少数据。多了一个   `pages`  代表已知的页，这个是由   `BigdataPaging`  的   `page_index`  （决定当前在哪页） 和   `one_side_page_count`  （决定前后加载几页）决定的。还有一个关键的   `BigdataCursor`  ，它指示当前页面的数据在原始数据集合中的对应位置。

总结一下就是，以前的分页方式中，同一数据在原始数据集合和其分页视图中的位置是相同的，而大数据分页中，这两者是不相同的，  `data_cursor`  和   `page_index`  分别指示同一数据在原始数据集合和分页视图中的位置，在两个视图之间建立了映射关系。



有了大数据分页，剩下的就是过滤阶段的算法了，这部分算法还是比较复杂的。基本逻辑就是去 ES 查一部分数据，然后经过子产品 RPC 过滤可见性，用过滤后的数据填充分页，直到填满请求的页数。这里需要处理一些边界条件，比如向后查询是否能查满期望的页数、向前查询不能小于第一页等等，另外实际执行是同时进行向前向后查询的。这部分代码在   `src/modules/search/services/search.service.ts`  ，有兴趣的同学可以自行查看。

#### 题外话：大数据分页的更多用途

这个分页方式我起名叫做大数据分页，并不只是为了支持此处的搜索场景，还希望替换其他涉及到大数据分页场景的交互方式。之前的分页方式使用 page_index 和 page_size 来定位，意味着必须从第一页开始翻到 page_index 才能获得对应数据，当面对大数据量时，这是十分低效的检索方式（在人机交互层面和在底层数据查找层面）。

问自己几个问题：

- 当进行搜索时，你是否期望能在第一页就看到你搜索的结果，你有多大概率会翻到第二页甚至是第三页？
- 当面对大数据量时，你会愿意一页一页翻找你需要的数据吗？
- 当面对大数据量时，跳页翻找还有意义吗？
- 当面对大数据量时，你会关心有多少数据吗？


回答完这几个问题，就能明白为什么  `BigdataPagination`  被设计成这样。

再来到技术层面。现有的分页查找方式性能很差，在一些业务场景已经频繁出现查询超时的情况。在设计大数据分页的时候，我是考虑它在能大致兼容上层分页方式的同时，支持将底层根据 skip+limit 的查找方式改为根据 sort_condition+limit 的查找方式。这里将 sort_condition 的值作为   `data_cursor`  ，即可在数据查找阶段利用 sort_condition   **索引**  快速定位指定页的数据。另外再抛弃掉 count 避免计算 count 的耗时。这样整个分页查找方法就会非常之快。



## 最后

纵观上面提到的各点技术改动，大家应该能发现，它们的前提，要么是实现产品功能，要么是优化产品体验，然后才是在不影响产品功能的基础上考虑最优的技术方案，尽量做到更合理的技术实现，和更少的维护成本。抛开产品和业务场景谈技术优化，是没什么太大意义的。共勉。

